---
title: "Clustering"
author: "Yifei Xu"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo = FALSE}
#Read in .csv and do basic wrangling
setwd("C:/xxx/xxx")
data <- read.csv("energy_weather.csv")
data <- data[,-c(1,2,17,18,19,21,24,25,34,36)]
names(data) <- c("g1","g2","g3","g4","g5","g6","g7","g8","g9","g10","g11","g12","g13","g14","LOAD","PRICE","tmp","prs","hmd","w_s","w_d","r_1","r_3","s_3","cld","p_h")
```


```{r echo = FALSE}
#Kmeans Clustering
library(dplyr)
library(ggplot2)
library(tidyr)
library(RColorBrewer)

#remove category
data <- data[,-c(26)]

#scale data
data <- data.frame(scale(data[,c("g1","g2","g3","g4","g5","g6","g7","g8","g9","g10","g11","g12","g13","g14","LOAD","PRICE","tmp","prs","hmd","w_s","w_d","r_1","r_3","s_3","cld")]))

# min.max.norm <-function(x){
#     (x-min(x))/(max(x)-min(x))
# }
# 
# data <- data.frame(g1=min.max.norm(data[,1]),g2=min.max.norm(data[,2]),g3=min.max.norm(data[,3]),g4=min.max.norm(data[,4]),g5=min.max.norm(data[,5]),g6=min.max.norm(data[,6]),g7=min.max.norm(data[,7]),g8=min.max.norm(data[,8]),g9=min.max.norm(data[,9]),g10=min.max.norm(data[,10]),g11=min.max.norm(data[,11]),g12=min.max.norm(data[,12]),g13=min.max.norm(data[,13]),g14=min.max.norm(data[,14]),PRICE=min.max.norm(data[,15]),LOAD=min.max.norm(data[,16]),tmp=min.max.norm(data[,17]),prs=min.max.norm(data[,18]),hmd=min.max.norm(data[,19]),w_s=min.max.norm(data[,20]),w_d=min.max.norm(data[,21]),r_1=min.max.norm(data[,22]),r_3=min.max.norm(data[,23]),s_3=min.max.norm(data[,24]),cld=min.max.norm(data[,25]))

#remove target
data_kmeans <- data[,-c(15)]

#cluster try
set.seed(123)
try.cluster <- kmeans(data_kmeans,7)
#data$try <- as.factor(try.cluster$cluster)

#find optimal k
kmean_withinss <- function(k) {
    cluster <- kmeans(data_kmeans, k, nstart=20, iter.max=80)
    return (cluster$tot.withinss)
}

kmean_betweenss <- function(k) {
    cluster <- kmeans(data_kmeans, k, nstart=20, iter.max=80)
    return (cluster$totss)
}

# Set maximum cluster 
max_k <- 20 
# Run algorithm over a range of k 
wss <- sapply(2:max_k, kmean_withinss)
# bss <- sapply(2:max_k, kmean_betweenss)
# 
# elb = wss/bss

# Create a data frame to plot the graph
elbow <-data.frame(2:max_k, wss)
# elbow <-data.frame(2:max_k, elb)

# Plot the graph with gglop
ggplot(elbow, aes(x = X2.max_k, y = wss)) +
    geom_point(size =1.5,color="seagreen") +
    geom_line(size =0.5,color="rosybrown") +
    scale_x_continuous(breaks = seq(1, 20, by = 1)) + theme_bw() + theme(panel.border=element_blank(),panel.grid.major = element_blank(),panel.grid.minor = element_blank(),axis.line=element_line(color="black"))

# ggplot(elbow, aes(x = X2.max_k, y = elb)) +
#     geom_point(size =1.5,color="seagreen") +
#     geom_line(size =0.5,color="rosybrown") +
#     scale_x_continuous(breaks = seq(1, 20, by = 1)) + theme_bw() + theme(panel.border=element_blank(),panel.grid.major = element_blank(),panel.grid.minor = element_blank(),axis.line=element_line(color="black"))
#k is 8
```


```{r}
#examine the cluster
cluster_k8 <-kmeans(data_kmeans, 8, nstart=20, iter.max = 80)
center <- cluster_k8$centers

#size histogram
size <- cluster_k8$size
data$kmeans <- as.numeric(cluster_k8$cluster)
ggplot(data,aes(kmeans))+geom_histogram(col="rosybrown",fill="seagreen",alpha=0.5)+
     scale_x_continuous(breaks = seq(1, 8, by = 1)) + theme_bw() + theme(panel.border=element_blank(),panel.grid.major = element_blank(),panel.grid.minor = element_blank(),axis.line=element_line(color="black"))

#create heat map
#prepare dataframe
cluster <- c(1:8)
center_df <- data.frame(cluster, center)


#center_reshape
center_reshape <- gather(center_df, features, values, g1: cld)

# Create the palette
hm.palette <-colorRampPalette(rev(brewer.pal(5, 'PiYG')),space='Lab')

# Plot the heat map
ggplot(data = center_reshape, aes(x = features, y = cluster, fill = values)) +
    scale_y_continuous(breaks = seq(1, 8, by = 1)) +
    geom_tile() +
    coord_equal() +
    scale_fill_gradientn(colours = hm.palette(90)) +
    theme_classic()+ theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))

# data$kmeans <- as.factor(data$kmeans)
# #scatterplot sample
# ggplot(data, aes(x=PRICE,y=g3,col=kmeans))+
#   geom_point(alpha=0.5)+
#   labs(
#     x="",
#     y="",
#     title = ""
#   )+ theme_bw() + theme(panel.border=element_blank(),panel.grid.major = element_blank(),panel.grid.minor = element_blank(),axis.line=element_line(color="black"))
#   )
```


```{r echo = FALSE}
#Hierarchical Clustering
library(tidyverse)  # data manipulation
library(cluster)    # clustering algorithms
library(factoextra) # clustering visualization
library(dendextend) # for comparing two d endrograms

data_hcc <- data_kmeans

# Dissimilarity matrix
d <- dist(data_hcc, method = "euclidean")

# Hierarchical clustering using Complete Linkage
# Plot the obtained dendrogram
memory.limit(size=15000)

# hc1 <- hclust(d, method = "single" )
# plot(hc1, hang = -1, ann = FALSE)
# 
# hc2 <- hclust(d, method = "average")
# plot(hc2, hang = -1, ann = FALSE)
# 
# hc3 <- hclust(d, method = "median")
# plot(hc3, hang = -1, ann = FALSE)
# 
# hc4 <- hclust(d, method = "complete")
# plot(hc4, hang = -1, ann = FALSE)
# 
# hc5 <- hclust(d, method = "centroid")
# plot(hc5, hang = -1, ann = FALSE)

hc6 <- hclust(d, method = "ward.D")
plot(hc6, hang = -1, ann = FALSE)
rect.hclust(hc6, k=6, border=2:7)
#k is 5
```


```{r echo = FALSE}
#draw heatmap
memb <- cutree(hc6, k = 6)
hist(memb)

#paste cluster
row.names(data_hcc) <- paste(memb,": ", row.names(data), sep = "")

memory.limit(size=150000)
# heatmap(as.matrix(data_hcc), Colv = NA, hclustfun = hclust, 
#         col=rev(paste("grey",1:99,sep="")))


dend <- as.dendrogram(hc6) %>% color_branches(k=6)
  
some_col_func <- rev(colorspace::heat_hcl(8, c = c(90,40),l = c(50,90), power = c(1/3, 1.5)))

heatmap_hhc <- gplots::heatmap.2(as.matrix(data_hcc), 
          scale="row",
          srtCol = 45,
          dendrogram = "row",
          Rowv = dend,
          Colv = "NA", # this to make sure the columns are not ordered
          trace="none",          
          margins =c(8,2),      
          denscol = "grey",
          density.info = "density",
          col = some_col_func
         )
data$hierarchical <- as.factor(memb)
```


```{r echo = FALSE}
#Multiple Regression

```


```{r echo = FALSE}
library(car)
library(forecast)
#Read in .csv and do basic wrangling
setwd("C:/Users/XYF_9/Desktop/Analyzing Big Data II/energy-consumption-generation-prices-and-weather")
data <- read.csv("energy_weather.csv")
data <- data[,-c(1,2,17,18,19,21,24,25,34,36)]
names(data) <- c("g1","g2","g3","g4","g5","g6","g7","g8","g9","g10","g11","g12","g13","g14","LOAD","PRICE","tmp","prs","hmd","w_s","w_d","r_1","r_3","s_3","cld","p_h")

#add kmeans and hierarchical labels
data$kmeans <- as.factor(cluster_k8$cluster)
data$hierarchical <- as.factor(memb)

write.csv(data,file="C:/Users/XYF_9/Desktop/1.csv",quote=F,row.names = F)

#remove outliers
data <- data[-c(25126,25162,25172,25165,834,832,833,836,29316,830,835,831,838,837,839,840,829,860,828,2026,858,827,841,812,857,865,816,859,861,864,813,815,29963,26325,12135,888,863,817,885,826,814,881,20173,12185,873,856,11230,26323,880,70,1218,30882),]

#seperate the dataset
set.seed(1)
train.index <- sample(nrow(data),round(nrow(data))*0.8)
train <- data[train.index,]
valid <- data[-train.index,]
```


```{r}
#multiple regression-kmeans
#train the model
load.mdl <- lm(LOAD ~ .-PRICE -g10 -r_1 -r_3 -cld -hierarchical, data = train)
vif(load.mdl)
summary(load.mdl)
accuracy(load.mdl$fitted.values, train$LOAD)

#validate the model
load.mdl.pred <- predict(load.mdl, valid)
accuracy(load.mdl.pred, valid$LOAD)

#Evaluate the model
par(mfrow=c(2,2))
plot(load.mdl)

#plot residuals
ggplot(load.mdl,aes(x=load.mdl$residuals)) +theme_bw()+ geom_histogram(aes(y=..density..),alpha=.4) + geom_density(color="pink2",size=1.3)+
  stat_function(fun = dnorm,alpha=0.8,lwd=0.6, args = list(mean = mean(load.mdl$residuals), sd = sd(load.mdl$residuals)))+labs(x= "Residuals",y="",title = "Histogram of Regression Residuals")+  theme(panel.border=element_blank(),panel.grid.major = element_blank(),panel.grid.minor = element_blank(),axis.line=element_line(color="black"))
```

```{r}
#multiple regression-hcc
#train the model
load.mdl <- lm(LOAD ~ .-PRICE -g10 -r_1 -r_3 -cld -kmeans, data = train)
vif(load.mdl)
summary(load.mdl)
accuracy(load.mdl$fitted.values, train$LOAD)

#validate the model
load.mdl.pred <- predict(load.mdl, valid)
accuracy(load.mdl.pred, valid$LOAD)

#Evaluate the model
par(mfrow=c(2,2))
plot(load.mdl)

#plot residuals
ggplot(load.mdl,aes(x=load.mdl$residuals)) +theme_bw()+ geom_histogram(aes(y=..density..),alpha=.4) + geom_density(color="pink2",size=1.3)+
  stat_function(fun = dnorm,alpha=0.8,lwd=0.6, args = list(mean = mean(load.mdl$residuals), sd = sd(load.mdl$residuals)))+labs(x= "Residuals",y="",title = "Histogram of Regression Residuals")+  theme(panel.border=element_blank(),panel.grid.major = element_blank(),panel.grid.minor = element_blank(),axis.line=element_line(color="black"))
```